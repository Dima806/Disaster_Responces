{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dima806/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dima806/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/dima806/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 dima806 6438912 Nov  4 19:33 InsertDatabaseName.db\n",
      "-rw-rw-r-- 1 dima806 6795264 Nov  4 19:34 DisasterResponse.db\n",
      "-rw-rw-r-- 1 dima806 6438912 Nov 16 16:35 DisasterMessagesDatabase.db\n"
     ]
    }
   ],
   "source": [
    "ls -lotr *db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 dima806 6438912 Nov 18 07:02 workspace/data/DisasterMessagesDatabase.db\n"
     ]
    }
   ],
   "source": [
    "! ls -lotr workspace/data/*db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26015, 40)\n"
     ]
    }
   ],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterMessagesDatabase.db')\n",
    "df = pd.read_sql_table('DisasterMessagesDatabase', engine)\n",
    "print(df.shape)\n",
    "X = df.message.values\n",
    "y = df.drop(['id', 'message', 'original', 'genre'], axis=1).values\n",
    "#y = df[['related', 'request']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26015, 40), (26015,), (26015, 36))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['direct', 'social', 'news'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.genre.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct     True   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct     True   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products      ...        \\\n",
       "0    False  False        False         False             False      ...         \n",
       "1    False  False         True         False             False      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm   fire  \\\n",
       "0        False                 False            False   False  False  False   \n",
       "1        False                 False             True   False   True  False   \n",
       "\n",
       "   earthquake   cold  other_weather  direct_report  \n",
       "0       False  False          False          False  \n",
       "1       False  False          False          False  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "direct    10696\n",
       "news      12960\n",
       "social     2359\n",
       "Name: message, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_counts = df.groupby('genre').count()['message']\n",
    "genre_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['direct', 'news', 'social']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_names = list(genre_counts.index)\n",
    "genre_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['direct', 'social', 'news'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.genre.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['related',\n",
       " 'request',\n",
       " 'offer',\n",
       " 'aid_related',\n",
       " 'medical_help',\n",
       " 'medical_products',\n",
       " 'search_and_rescue',\n",
       " 'security',\n",
       " 'military',\n",
       " 'child_alone',\n",
       " 'water',\n",
       " 'food',\n",
       " 'shelter',\n",
       " 'clothing',\n",
       " 'money',\n",
       " 'missing_people',\n",
       " 'refugees',\n",
       " 'death',\n",
       " 'other_aid',\n",
       " 'infrastructure_related',\n",
       " 'transport',\n",
       " 'buildings',\n",
       " 'electricity',\n",
       " 'tools',\n",
       " 'hospitals',\n",
       " 'shops',\n",
       " 'aid_centers',\n",
       " 'other_infrastructure',\n",
       " 'weather_related',\n",
       " 'floods',\n",
       " 'storm',\n",
       " 'fire',\n",
       " 'earthquake',\n",
       " 'cold',\n",
       " 'other_weather',\n",
       " 'direct_report']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['id', 'message', 'original', 'genre'], axis=1).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 36)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPLIST = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS))\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"”\", \"”\"]\n",
    "len(STOPLIST), len(SYMBOLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_stem(text):\n",
    "\n",
    "    tokens = TweetTokenizer().tokenize(text.lower())\n",
    "    stemmer = SnowballStemmer('english') # better than PorterStemmer(), see http://www.nltk.org/howto/stem.html\n",
    "    \n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = stemmer.stem(tok).strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "    clean_tokens = [tok for tok in clean_tokens if tok not in STOPLIST]\n",
    "    clean_tokens = [tok for tok in clean_tokens if tok not in SYMBOLS]\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lemma(text):\n",
    "\n",
    "    tokens = TweetTokenizer().tokenize(text.lower())\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = [lemmatizer.lemmatize(tok).strip() for tok in tokens]\n",
    "    clean_tokens = [tok for tok in clean_tokens if tok not in STOPLIST]\n",
    "    clean_tokens = [tok for tok in clean_tokens if tok not in SYMBOLS]\n",
    "\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346837"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'].apply(lambda x: len(tokenize_lemma(x))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('UN reports Leogane 80-90 destroyed. Only Hospital St. Croix functioning. Needs supplies desperately.',\n",
       " ['report',\n",
       "  'leogane',\n",
       "  '80-90',\n",
       "  'destroyed',\n",
       "  'hospital',\n",
       "  'st',\n",
       "  'croix',\n",
       "  'functioning',\n",
       "  'need',\n",
       "  'supply',\n",
       "  'desperately'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3,'message'], tokenize_lemma(df.loc[3,'message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "- You'll find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scoring_func(y, y_pred):\n",
    "#     '''\n",
    "#     Returns mean accuracy score\n",
    "    \n",
    "#     Args:\n",
    "#         y (np.array of floats):\n",
    "#         y_pred (np.array of floats):\n",
    "#     Returns:\n",
    "#         score (float): score\n",
    "#     '''\n",
    "#     return (y == y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_func(y, y_pred):\n",
    "    '''\n",
    "    Returns mean weighted F-score (important for Grid CV search)\n",
    "    \n",
    "    Args:\n",
    "        y (np.array of floats):\n",
    "        y_pred (np.array of floats):\n",
    "    Returns:\n",
    "        score (float): score\n",
    "    '''\n",
    "\n",
    "    return np.mean([f1_score(y[:,i], y_pred[:,i], average='weighted') for i in range(y_pred.shape[1])]) # new scoring  \n",
    "#     return f1_score(y, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display_results(y_test, y_test_pred, y_train, y_train_pred):\n",
    "#     test_labels = np.unique(y_test_pred)\n",
    "#     test_accuracy = scoring_func(y_test, y_test_pred)\n",
    "#     train_labels = np.unique(y_train_pred)\n",
    "#     train_accuracy = scoring_func(y_train, y_train_pred)\n",
    "\n",
    "#     print(\"Test labels:\", test_labels)\n",
    "#     print(\"Test accuracy:\", test_accuracy)\n",
    "#     print(\"Train labels:\", train_labels)\n",
    "#     print(\"Train accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes) classifier that [provides a nice baseline](https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568) for topic classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize_lemma, stop_words='english')),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "       ('clf', MultiOutputClassifier(MultinomialNB()))])\n",
    "#        ('clf', MultiOutputClassifier(XGBClassifier()))\n",
    "#    ])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 83\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.8 s, sys: 15.5 ms, total: 4.81 s\n",
      "Wall time: 4.82 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        ...ssifier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.1 s, sys: 3.92 ms, total: 1.1 s\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.22      0.00      0.00      1214\n",
      "       True       0.77      1.00      0.87      3989\n",
      "\n",
      "avg / total       0.64      0.77      0.67      5203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test[:,0], y_test_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.895266497966738"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score = scoring_func(y_test, y_test_pred)\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {\n",
    "#     'vect__ngram_range': [(1, 2)],\n",
    "#     'vect__max_df': [0.8],\n",
    "#     'vect__max_features': [None],\n",
    "#     'tfidf__use_idf': [True],\n",
    "#     'clf__estimator__n_estimators': [100], # add here __estimator as in https://goo.gl/bDiZKM\n",
    "# }\n",
    "\n",
    "# cv = GridSearchCV(pipeline, param_grid=parameters, verbose=2, scoring=make_scorer(scoring_func))\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vect__max_df': [0.125, 0.25, 0.5, 1.0],\n",
    "    'vect__min_df': [1, 2, 5, 10],\n",
    "    'vect__max_features': [None, 5000, 10000, 20000],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'clf__estimator__alpha': [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0], # add here __estimator as in https://goo.gl/bDiZKM\n",
    "}\n",
    "\n",
    "n_iter = 100 # number of random picks\n",
    "\n",
    "cv = RandomizedSearchCV(pipeline, param_distributions=parameters, \n",
    "                        n_iter=n_iter, cv=3, verbose=2, \n",
    "                        scoring=make_scorer(scoring_func), random_state=83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   5.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   5.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   5.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   7.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   6.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   6.8s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   5.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   6.1s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   6.1s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   6.2s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   6.3s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   4.6s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   5.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   5.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   4.4s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   5.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   5.2s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   7.4s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   7.1s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   7.0s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=5000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   4.4s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   5.6s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   5.7s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   5.7s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   6.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   7.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   6.9s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=None, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   6.1s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   6.1s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   6.1s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=1.0, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=1.0 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=10, vect__max_features=5000, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=1.0, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=20000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   6.1s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   6.1s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   6.1s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=5, vect__max_features=10000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   5.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   5.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.01, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=5, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   5.1s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=False, clf__estimator__alpha=0.02, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   6.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   6.2s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.2, total=   6.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   4.6s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   4.5s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=5000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.5, total=   5.0s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   6.3s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   6.3s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   6.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   4.5s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=10, vect__max_features=20000, vect__max_df=0.25, tfidf__use_idf=True, clf__estimator__alpha=0.01, total=   4.6s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   7.8s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   6.3s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=5, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   6.1s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   6.2s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   6.4s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=1, vect__max_features=20000, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.1, total=   6.2s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   4.5s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   4.5s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.5 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=1, vect__max_features=None, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.5, total=   4.5s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   5.4s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   5.5s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=20000, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   5.4s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   6.2s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   6.2s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.05, total=   6.1s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   5.8s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   5.9s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.2 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=1, vect__max_features=None, vect__max_df=1.0, tfidf__use_idf=True, clf__estimator__alpha=0.2, total=   5.8s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.3s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.9s\n",
      "[CV] vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.1 \n",
      "[CV]  vect__ngram_range=(1, 1), vect__min_df=2, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=False, clf__estimator__alpha=0.1, total=   4.6s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   6.1s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   6.2s\n",
      "[CV] vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.05 \n",
      "[CV]  vect__ngram_range=(1, 3), vect__min_df=10, vect__max_features=10000, vect__max_df=0.125, tfidf__use_idf=True, clf__estimator__alpha=0.05, total=   6.2s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   5.4s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   5.4s\n",
      "[CV] vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.02 \n",
      "[CV]  vect__ngram_range=(1, 2), vect__min_df=2, vect__max_features=None, vect__max_df=0.5, tfidf__use_idf=True, clf__estimator__alpha=0.02, total=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed: 41.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        ...ssifier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "           n_jobs=1))]),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=1,\n",
       "          param_distributions={'vect__ngram_range': [(1, 1), (1, 2), (1, 3)], 'vect__max_df': [0.125, 0.25, 0.5, 1.0], 'vect__min_df': [1, 2, 5, 10], 'vect__max_features': [None, 5000, 10000, 20000], 'tfidf__use_idf': [True, False], 'clf__estimator__alpha': [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0]},\n",
       "          pre_dispatch='2*n_jobs', random_state=83, refit=True,\n",
       "          return_train_score='warn', scoring=make_scorer(scoring_func),\n",
       "          verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9034911089642884, 0.895266497966738)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_score_, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=20000, min_df=5,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "       ...sifier(estimator=MultinomialNB(alpha=0.02, class_prior=None, fit_prior=True),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if cv.best_score_ > best_score:\n",
    "    best_score = cv.best_score_\n",
    "    best_model = cv.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__alpha': 0.02,\n",
       " 'tfidf__use_idf': False,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': 20000,\n",
       " 'vect__min_df': 5,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.2 s, sys: 3 µs, total: 1.2 s\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 0 related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.35      0.11      0.17      1214\n",
      "       True       0.78      0.94      0.85      3989\n",
      "\n",
      "avg / total       0.68      0.75      0.69      5203\n",
      "\n",
      ">>> 1 request\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.87      0.88      0.88      4306\n",
      "       True       0.41      0.39      0.40       897\n",
      "\n",
      "avg / total       0.79      0.80      0.80      5203\n",
      "\n",
      ">>> 2 offer\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       1.00      1.00      1.00      5178\n",
      "       True       0.00      0.00      0.00        25\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5203\n",
      "\n",
      ">>> 3 aid_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.61      0.75      0.67      3080\n",
      "       True       0.45      0.29      0.35      2123\n",
      "\n",
      "avg / total       0.54      0.56      0.54      5203\n",
      "\n",
      ">>> 4 medical_help\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.92      1.00      0.96      4784\n",
      "       True       0.00      0.00      0.00       419\n",
      "\n",
      "avg / total       0.85      0.92      0.88      5203\n",
      "\n",
      ">>> 5 medical_products\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      1.00      0.97      4925\n",
      "       True       0.00      0.00      0.00       278\n",
      "\n",
      "avg / total       0.90      0.95      0.92      5203\n",
      "\n",
      ">>> 6 search_and_rescue\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      1.00      0.99      5078\n",
      "       True       0.00      0.00      0.00       125\n",
      "\n",
      "avg / total       0.95      0.98      0.96      5203\n",
      "\n",
      ">>> 7 security\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      1.00      0.99      5110\n",
      "       True       0.00      0.00      0.00        93\n",
      "\n",
      "avg / total       0.96      0.98      0.97      5203\n",
      "\n",
      ">>> 8 military\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.97      1.00      0.98      5044\n",
      "       True       0.00      0.00      0.00       159\n",
      "\n",
      "avg / total       0.94      0.97      0.95      5203\n",
      "\n",
      ">>> 9 child_alone\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       1.00      1.00      1.00      5203\n",
      "\n",
      "avg / total       1.00      1.00      1.00      5203\n",
      "\n",
      ">>> 10 water\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      1.00      0.96      4849\n",
      "       True       0.00      0.00      0.00       354\n",
      "\n",
      "avg / total       0.87      0.93      0.90      5203\n",
      "\n",
      ">>> 11 food\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.89      0.99      0.93      4604\n",
      "       True       0.27      0.04      0.07       599\n",
      "\n",
      "avg / total       0.82      0.88      0.83      5203\n",
      "\n",
      ">>> 12 shelter\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.91      1.00      0.95      4741\n",
      "       True       0.00      0.00      0.00       462\n",
      "\n",
      "avg / total       0.83      0.91      0.87      5203\n",
      "\n",
      ">>> 13 clothing\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      1.00      0.99      5107\n",
      "       True       0.14      0.01      0.02        96\n",
      "\n",
      "avg / total       0.97      0.98      0.97      5203\n",
      "\n",
      ">>> 14 money\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      1.00      0.99      5094\n",
      "       True       0.00      0.00      0.00       109\n",
      "\n",
      "avg / total       0.96      0.98      0.97      5203\n",
      "\n",
      ">>> 15 missing_people\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      1.00      1.00      5154\n",
      "       True       0.00      0.00      0.00        49\n",
      "\n",
      "avg / total       0.98      0.99      0.99      5203\n",
      "\n",
      ">>> 16 refugees\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.97      1.00      0.98      5030\n",
      "       True       0.00      0.00      0.00       173\n",
      "\n",
      "avg / total       0.93      0.97      0.95      5203\n",
      "\n",
      ">>> 17 death\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      1.00      0.98      4966\n",
      "       True       0.00      0.00      0.00       237\n",
      "\n",
      "avg / total       0.91      0.95      0.93      5203\n",
      "\n",
      ">>> 18 other_aid\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.87      1.00      0.93      4505\n",
      "       True       0.25      0.00      0.00       698\n",
      "\n",
      "avg / total       0.78      0.87      0.80      5203\n",
      "\n",
      ">>> 19 infrastructure_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      1.00      0.96      4849\n",
      "       True       0.00      0.00      0.00       354\n",
      "\n",
      "avg / total       0.87      0.93      0.90      5203\n",
      "\n",
      ">>> 20 transport\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      1.00      0.98      4954\n",
      "       True       0.00      0.00      0.00       249\n",
      "\n",
      "avg / total       0.91      0.95      0.93      5203\n",
      "\n",
      ">>> 21 buildings\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      1.00      0.97      4920\n",
      "       True       0.00      0.00      0.00       283\n",
      "\n",
      "avg / total       0.89      0.94      0.92      5203\n",
      "\n",
      ">>> 22 electricity\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      1.00      0.99      5091\n",
      "       True       0.00      0.00      0.00       112\n",
      "\n",
      "avg / total       0.96      0.98      0.97      5203\n",
      "\n",
      ">>> 23 tools\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      1.00      1.00      5162\n",
      "       True       0.00      0.00      0.00        41\n",
      "\n",
      "avg / total       0.98      0.99      0.99      5203\n",
      "\n",
      ">>> 24 hospitals\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      1.00      0.99      5149\n",
      "       True       0.00      0.00      0.00        54\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5203\n",
      "\n",
      ">>> 25 shops\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      1.00      1.00      5173\n",
      "       True       0.00      0.00      0.00        30\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5203\n",
      "\n",
      ">>> 26 aid_centers\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      1.00      0.99      5138\n",
      "       True       0.00      0.00      0.00        65\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5203\n",
      "\n",
      ">>> 27 other_infrastructure\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      1.00      0.98      4965\n",
      "       True       0.00      0.00      0.00       238\n",
      "\n",
      "avg / total       0.91      0.95      0.93      5203\n",
      "\n",
      ">>> 28 weather_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.91      0.83      3731\n",
      "       True       0.56      0.30      0.39      1472\n",
      "\n",
      "avg / total       0.71      0.73      0.71      5203\n",
      "\n",
      ">>> 29 floods\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.92      0.99      0.96      4778\n",
      "       True       0.22      0.02      0.03       425\n",
      "\n",
      "avg / total       0.86      0.91      0.88      5203\n",
      "\n",
      ">>> 30 storm\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.91      0.99      0.95      4698\n",
      "       True       0.35      0.07      0.12       505\n",
      "\n",
      "avg / total       0.85      0.90      0.86      5203\n",
      "\n",
      ">>> 31 fire\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      1.00      0.99      5146\n",
      "       True       0.00      0.00      0.00        57\n",
      "\n",
      "avg / total       0.98      0.99      0.98      5203\n",
      "\n",
      ">>> 32 earthquake\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.92      0.99      0.95      4715\n",
      "       True       0.62      0.17      0.27       488\n",
      "\n",
      "avg / total       0.89      0.91      0.89      5203\n",
      "\n",
      ">>> 33 cold\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      1.00      0.99      5091\n",
      "       True       0.00      0.00      0.00       112\n",
      "\n",
      "avg / total       0.96      0.98      0.97      5203\n",
      "\n",
      ">>> 34 other_weather\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.94      1.00      0.97      4912\n",
      "       True       0.12      0.00      0.01       291\n",
      "\n",
      "avg / total       0.90      0.94      0.92      5203\n",
      "\n",
      ">>> 35 direct_report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.84      0.88      0.86      4182\n",
      "       True       0.39      0.32      0.35      1021\n",
      "\n",
      "avg / total       0.75      0.77      0.76      5203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(y_test.shape[1]):\n",
    "    print('>>>', i, df.drop(['id', 'message', 'original', 'genre'], axis=1).columns[i])\n",
    "    print(classification_report(y_test[:,i], y_test_pred[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried XGBClassifier() instead and add some text stats inspired by [this link]( https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer.html#sphx-glr-auto-examples-compose-plot-column-transformer-py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'length': len(text), \n",
    "                 'num_sentences': text.count('.'), \n",
    "                 'num_words': len(text.split())}\n",
    "                for text in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_pipeline():\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('text', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize_lemma, stop_words='english')),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "            ])),\n",
    "            ('body_stats', Pipeline([\n",
    "                ('stats', TextStats()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    "        ])),\n",
    "        ('clf', MultiOutputClassifier(XGBClassifier()))\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipeline = make_new_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 23s, sys: 2.65 s, total: 2min 26s\n",
      "Wall time: 2min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text', Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, ma...eg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "new_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_new = new_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8965308036416216"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_func(y_test, y_test_pred_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no significant improvement, so we continue with our best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9023774314044368\n"
     ]
    }
   ],
   "source": [
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(best_model, open(filename, 'wb'))\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = scoring_func(y_test, loaded_model.predict(X_test))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_classifier.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_classifier.py\n",
    "\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def load_data(database_filepath):\n",
    "    engine = create_engine('sqlite:///'+database_filepath)\n",
    "    df = pd.read_sql_table('DisasterMessagesDatabase', engine)\n",
    "    X = df.message.values\n",
    "    y = df.drop(['id', 'message', 'original', 'genre'], axis=1).values\n",
    "    category_names = df.drop(['id', 'message', 'original', 'genre'], axis=1).columns.tolist()\n",
    "    return X, y, category_names\n",
    "\n",
    "STOPLIST = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS))\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"”\", \"”\"]\n",
    "\n",
    "def tokenize(text):\n",
    "\n",
    "    tokens = TweetTokenizer().tokenize(text.lower())\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = [lemmatizer.lemmatize(tok).strip() for tok in tokens]\n",
    "    clean_tokens = [tok for tok in clean_tokens if tok not in STOPLIST]\n",
    "    clean_tokens = [tok for tok in clean_tokens if tok not in SYMBOLS]\n",
    "    \n",
    "    return clean_tokens\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize, \n",
    "                                 stop_words='english', \n",
    "                                 max_df=0.5, \n",
    "                                 max_features=20000,\n",
    "                                 min_df=5,\n",
    "                                 ngram_range=(1,2))),\n",
    "        ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "        ('clf', MultiOutputClassifier(MultinomialNB(alpha=0.02)))\n",
    "    ])\n",
    "        \n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, category_names):\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    for i, item in enumerate(category_names):\n",
    "        print('>>>', item)\n",
    "        print(classification_report(y_test[:,i], y_test_pred[:,i]))\n",
    "\n",
    "def save_model(model, model_filepath):\n",
    "    \n",
    "    pickle.dump(model, open(model_filepath, 'wb'))\n",
    "\n",
    "\n",
    "def main():\n",
    "    if len(sys.argv) == 3:\n",
    "        database_filepath, model_filepath = sys.argv[1:]\n",
    "        print('Loading data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "        X, Y, category_names = load_data(database_filepath)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "        \n",
    "        print('Building model...')\n",
    "        model = build_model()\n",
    "        \n",
    "        print('Training model...')\n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        print('Evaluating model...')\n",
    "        evaluate_model(model, X_test, Y_test, category_names)\n",
    "\n",
    "        print('Saving model...\\n    MODEL: {}'.format(model_filepath))\n",
    "        save_model(model, model_filepath)\n",
    "\n",
    "        print('Trained model saved!')\n",
    "\n",
    "    else:\n",
    "        print('Please provide the filepath of the disaster messages database '\\\n",
    "              'as the first argument and the filepath of the pickle file to '\\\n",
    "              'save the model to as the second argument. \\n\\nExample: python '\\\n",
    "              'train_classifier.py ../data/DisasterResponse.db classifier.pkl')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 dima806 4076 Nov 18 10:42 train_classifier.py\n"
     ]
    }
   ],
   "source": [
    "ls -lotr train_classifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
